{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tesi.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyObpu6NpmHEmEl97o3k1Lof",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LorenzoGianassi/Tesi/blob/master/Tesi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mJDX91hlXVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from timeit import default_timer as timer\n",
        "from torch.utils.data import Subset\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import copy\n",
        "from torch.backends import cudnn\n",
        "\n",
        "# associo cuda per lavorare ulla gpu\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "\n",
        "print(device)\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "# trovo gli indici e salvo una lista per ciascuno\n",
        "airplane_indices, automobile_indices = [], []\n",
        "bird_indices, other_indices = [], []\n",
        "cat_indices, deer_indices = [], []\n",
        "\n",
        "airplane_idx = trainset.class_to_idx['airplane']\n",
        "automobile_idx = trainset.class_to_idx['automobile']\n",
        "bird_idx = trainset.class_to_idx['bird']\n",
        "cat_idx = trainset.class_to_idx['cat']\n",
        "deer_idx = trainset.class_to_idx['deer']\n",
        "\n",
        "\n",
        "def train_split(trainset):\n",
        "    for i in range(len(trainset)):\n",
        "        current_class = trainset[i][1]\n",
        "        if current_class == automobile_idx:\n",
        "            automobile_indices.append(i)\n",
        "        elif current_class == deer_idx:\n",
        "            deer_indices.append(i)\n",
        "        elif current_class == airplane_idx:\n",
        "            airplane_indices.append(i)\n",
        "        elif current_class == bird_idx:\n",
        "            bird_indices.append(i)\n",
        "        elif current_class == cat_idx:\n",
        "            cat_indices.append(i)\n",
        "        else:\n",
        "            other_indices.append(i)\n",
        "    new_trainset1 = Subset(trainset, airplane_indices + automobile_indices  + cat_indices + deer_indices + bird_indices)\n",
        "    new_trainset2 = Subset(trainset, other_indices)\n",
        "    return new_trainset1, new_trainset2\n",
        "\n",
        "\n",
        "trainset1, trainset2 = train_split(trainset)\n",
        "#random.shuffle(trainset1)\n",
        "#random.shuffle(trainset2)\n",
        "\n",
        "trainloaderA = torch.utils.data.DataLoader(trainset1, batch_size=128,\n",
        "                                           shuffle=True, num_workers=0)\n",
        "trainloaderB = torch.utils.data.DataLoader(trainset2, batch_size=128,\n",
        "                                           shuffle=True, num_workers=0)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
        "                                          shuffle=True, num_workers=0)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
        "                                         shuffle=True, num_workers=0)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "class Net1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net1, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 5)\n",
        "        self.fc4 =nn.Linear (5,5)\n",
        "        self.fc4.bias.data=torch.zeros(fc4.bias.size())\n",
        "        self.fc4.weight.data=torch.randn(m.weight.size())*.01\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\"\"\"\n",
        "net = Net().to(device)\n",
        "\n",
        "print(\"Allocated:\", round(torch.cuda.memory_allocated(0) / 10243, 1), \"GB\")\n",
        "print(\"rete creata\")\n",
        "\n",
        "\n",
        "# metodo per eseguire il test\n",
        "def train(trainloader,optimizer,criterion,net):\n",
        "    for epoch in range(20):  # loop over the dataset multiple times\n",
        "        start = timer()\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                      (epoch + 1, i + 1, running_loss / 2000))\n",
        "                running_loss = 0.0\n",
        "        end = timer()\n",
        "        print(\"Tempo di una epoca: \", (end - start), \"sec\")\n",
        "    print('Finished Training')\n",
        "\n",
        "\n",
        "# metodo per eseguire il test\n",
        "def test(testloader,net):\n",
        "    # accuracy dell'intero network\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "            100 * correct / total))\n",
        "\n",
        "    # quale classe ha la migliore performance\n",
        "    class_correct = list(0. for i in range(10))\n",
        "    class_total = list(0. for i in range(10))\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            c = (predicted == labels).squeeze()\n",
        "            for i in range(4):\n",
        "                label = labels[i]\n",
        "                class_correct[label] += c[i].item()\n",
        "                class_total[label] += 1\n",
        "\n",
        "    for i in range(10):\n",
        "        print('Accuracy of %5s : %2d %%' % (\n",
        "            classes[i], 100 * class_correct[i] / class_total[i]))\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "cudnn.benchmark = True\n",
        "\n",
        "# eseguo train\n",
        "train(trainloaderA,optimizer,criterion,net)\n",
        "\n",
        "test(testloader,net)\n",
        "\n",
        "PATH = './cifar_net.pth'\n",
        "torch.save(net.state_dict(),PATH )\n",
        "#torch.save(optimizer.state_dict(), PATH)\n",
        "\n",
        "#fc4.weight.data=torch.randn(fc4.weight.size())*.01 #Random weight initialisation\n",
        "#fc4.bias.data=torch.zeros(fc4.bias.size())\n",
        "net.load_state_dict(torch.load(PATH), strict=False)\n",
        "#optimizer.load_state_dict(torch.load(PATH))\n",
        "net.eval()\n",
        "\"\"\"\n",
        "# net = Net()\n",
        "net_dict = net.state_dict()\n",
        "net1 = Net()\n",
        "net1.to(device)\n",
        "net1_dict = net1.state_dict()\n",
        "pretrained_dict = net_dict\n",
        "model_dict = net1_dict\n",
        "# 1. filter out unnecessary keys\n",
        "pretrained_dict = {k: v for k, v in net_dict.items() if k in model_dict}\n",
        "# 2. overwrite entries in the existing state dict\n",
        "model_dict.update(net_dict)\n",
        "# 3. load the new state dict\n",
        "net1.load_state_dict(model_dict)\n",
        "net1 = net1.eval()\n",
        "\"\"\"\n",
        "\n",
        "#for param in net.parameters():\n",
        "#   param.requires_grad = False\n",
        "\n",
        "\n",
        "# Parameters of newly constructed modules have requires_grad=True by default\n",
        "\n",
        "#net1.fc4.weight.data=torch.randn(net1.fc4.weight.size())*.01 #Random weight initialisation\n",
        "#net1.fc3.bias.data=torch.zeros(net1.fc3.bias.size())\n",
        "\n",
        "net.fc3 = nn.Linear(84,10)\n",
        "net.add_module(\"fc4\",nn.Linear(84,10))  \n",
        "net.fc4.weight.data = torch.randn(net.fc4.weight.size())*.01\n",
        "net = net.to(device)\n",
        "\n",
        "# Observe that only parameters of final layer are being optimized as\n",
        "# opposed to before.\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train(trainloaderB,optimizer,criterion, net)\n",
        "\n",
        "# eseguo test\n",
        "test(testloader,net)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}