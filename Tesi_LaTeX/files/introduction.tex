\chapter{Introduzione}\label{ch:introduzione}
\section*{Motivazioni}
Gli esseri umani e gli animali hanno la capacità di acquisire, perfezionare e modificare continuamente le proprie conoscenze e abilità per tutta la durata della loro vita. Questa capacità, chiamata \textit{Continual Learning}, è composta da una ricca serie di meccanismi \textit{neurocognitivi} che insieme contribuiscono allo sviluppo e alla specializzazione delle nostre abilità sensomotorie, nonché al rafforzamento e al recupero della memoria a lungo termine. Di conseguenza, l'applicazione del \textit{Continual Learning} a  \textit{sistemi computazionali} e \textit{agenti autonomi} che interagiscono nel mondo reale ed elaborano flussi continui di informazioni può essere di  fondamentale importanza. Tuttavia, il \textit{Continual Learning} rimane una sfida di lunga data per il \textit{Machine Learning} e i modelli di \textit{Rete Neurale} poiché l'acquisizione continua di informazioni disponibili in modo incrementale da distribuzioni di dati non stabili generalmente porta ad ottenere il \textit{Catastrophic Forgetting}, concetto che andremo a definire successivamente.\newline
Questo rappresenta un grave problema per i modelli di \textit{Rete Neurale} moderni che in genere apprendono rappresentazioni da \textit{batch} stazionari di dati di \textit{Training}, quindi senza tenere conto delle situazioni in cui le informazioni diventano disponibili. Di conseguenza, la capacità  di apprendere da un flusso continuo  senza avere una perdita di memoria sui dati precedenti potrebbe avvicinare l'apprendimento delle \textit{reti neurali} a quello dell'essere umano con sviluppi interessanti per la scienza.
\section*{Presentazione del Lavoro}
In questo elaborato di tesi, partendo dal lavoro di \cite{Continual_Learning}, verrà descritto il concetto \textit{Continual Learning} mostrandone i pregi e le difficoltà(\textit{Catastrophic Forgetting}) tramite un problema di \textit{Visual Recognition}. Per fare ciò è stato implementato un \textit{framework} che fosse in grado di eseguire una \textit{Pipeline}, che avrà il compito di eseguire l'apprendimento svolto da un modello per il \textit{Continual Learning} mostrando l'occorrere del \textit{forgetting}. Prima di mostrare i risultati ottenuti verranno descritti i concetti a livello teorico e presentati gli strumenti utilizzati durante la \textit{Pipeline}.\newline
Il lavoro descritto è diviso in tre parti: la prima relativa al \textit{Joint-Train} e le ultime due alle configurazioni \textit{Task Agnostic/Task Aware}. Successivamente, sarà presentata una soluzione molto \textit{naïve} ispirata dal \textit{paper} \cite{Continual_Learning}.
