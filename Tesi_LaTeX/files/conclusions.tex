\chapter{Conclusioni}\label{ch:conclusioni}
\section{Risultati}
Il lavoro che è stato descritto in questo elaborato di tesi può essere ritenuto soddisfacente. Il nostro intento era quello di rappresentare al meglio il \textbf{Continual Learning} e il suo problema del \textbf{Catastrophic Forgetting}, perciò nella nostra \textit{pipeline} non è stato inserito nessun metodo che potesse alleviare o bloccare tale problema. Abbiamo potuto osservare come il \textit{training} effettuato in fasi diverse per ciascun \textit{task} abbia portato al \textit{forgetting}, valutandolo sia nel caso \textit{Task-Aware} che \textit{Task-Agnostic}.\newline
È stato riscontrato un \textit{forgetting} minore nelle configurazioni in cui è stato applicato il \textit{Task-Aware Test}, peggiore con \textit{Task-Agnostic Test}. Per questo motivo è stato scelto come caso interessante, su cui applicare una soluzione basata \textit{Replay-Based Methods}, \textit{Task-Agnostic Training/Task-Agnostic Test}.
Con tale soluzione è stato possibile ottenere dei risultati migliori rispetto ai precedenti. Infatti, questa configurazione soffriva del \textit{Task Rececncy Bias} che portava a dimenticare completamente i parametri dei \textit{tasks} precedenti all'ultimo visionato. Usando un numero di esempi limitato per fare il \textit{replay} siamo riusciti ad avvicinarci al \textit{Joint-Train}, mantenendo comunque un \textit{forgetting} elevato.
La rete neurale sviluppata non è ovviamente \textbf{immune} da \textbf{errori}, potrebbero essere apportate delle migliorie in modo tale da adattarsi meglio al problema in esame, ottenendo  risultati migliori.
\section{Sviluppi Futuri}
Negli esperimenti eseguiti in questo elaborato, abbiamo considerato un ambiente di apprendimento basato sul concetto \textit{Task Incremental}. In questo \textit{setting} i \textit{tasks} vengono ricevuti sequenzialmente e il \textit{Training}  viene eseguito sui dati di addestramento associati. È, quindi, richiesta la conoscenza dei limiti dei \textit{tasks} (ovvero quando i \textit{tasks} cambiano), consentendo più passaggi su grandi \textit{batch} di dati di \textit{training}. Può essere, quindi, un rilassamento del sistema di \textit{Continual Learning} desiderato che è più probabile incontrare nella pratica. Una evoluzione potrebbe essere quella di rendere il modello capace di processare dati di \textit{tasks} diversi senza considerarne i limiti, al fine di riconoscere se l'\textit{input} appartiene a un \textit{task} già osservato. Questa modifica potrebbe conferire grande flessibilità al metodo del \textit{Continual Learning} rendendolo applicabile a qualsiasi scenario in cui i dati arrivano con uno \textit{stream} infinito.
\newline
Un altro sviluppo possibile, potrebbe essere quello di utilizzare un dataset diverso. Sarebbe appunto interessante osservare i risultati all'aumentare del numero di classi presenti nel dataset, o altrimenti, all'aumentare del numero di esempi presenti nel \textit{trainset} e \textit{testset}. Un dataset che viene spontaneamente in mente dopo la lettura di questo elaborato è \textit{CIFAR-100}. Quest'ultimo non è altro che una estensione di \textit{CIFAR-10}(utilizzato in questo elaborato), composto da 100 \textit{classi} differenti. Tale modifica ci consentirebbe di visualizzare più \textit{tasks} e con un numero di classi associato maggiore.\newline
Infine, nella soluzione che abbiamo esposto per alleviare il \textit{forgetting} non è stata attuata nessuna tecnica per sceglie gli esempi su cui fare il \textit{replay}, quindi una direzione di sviluppo potrebbe essere questa. Come viene descritto in \cite{Continual_Learning}, esistono dei metodi specifici del \textbf{Reaplay Based Methods}:
\textit{iCaRL} e \textit{GEM}. In particolare, questi due metodi attuano delle politiche per la scelta degli esempi utilizzati nel \textit{replay}.
\textit{iCaRL} si basa sulla stima della \textit{Loss}, mentre \textit{GEM} si concentra sul \textit{gradiente}.